{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mario-rot/Introduction-to-Human-Language-Technology/blob/main/Project_LaurenTucker_MarioRosas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpEp-jhafvsx"
      },
      "source": [
        "# Lab session 7 (Word Sequences) - ILTH\n",
        "\n",
        "**Students:** Lauren Tucker & Mario Rosas !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0LXucmalIYk"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zTBIq_k_3Yb",
        "outputId": "21414362-13fe-4e6a-8cc4-c4857505aa25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Introduction-to-Human-Language-Technology'...\n",
            "remote: Enumerating objects: 864, done.\u001b[K\n",
            "remote: Counting objects: 100% (864/864), done.\u001b[K\n",
            "remote: Compressing objects: 100% (792/792), done.\u001b[K\n",
            "remote: Total 864 (delta 117), reused 788 (delta 67), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (864/864), 2.27 MiB | 14.46 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "git clone https://github.com/mario-rot/Introduction-to-Human-Language-Technology.git\n",
        "cd 'Introduction-to-Human-Language-Technology'\n",
        "mv 'Complementary Material' /content/\n",
        "\n",
        "pip install svgling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mi9UgnrHx1NN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from text_processing import text_processing, compute_metrics\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "dt = pd.read_csv('Complementary Material/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "dt['gs'] = pd.read_csv('Complementary Material/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW6chj7pBMrs"
      },
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading the data to the text processing class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uqvz4ye8TEVJ"
      },
      "outputs": [],
      "source": [
        "sentences_1 = dt[0]\n",
        "sentences_2 = dt[1]\n",
        "\n",
        "tp1 = text_processing(sentences_1)\n",
        "tp2 = text_processing(sentences_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.3971297709735512, pvalue=8.622653547988135e-19)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([sentences_1, sentences_2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing with data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4679440754704449, pvalue=2.358310094026997e-26)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.clean_data(), tp2.clean_data()], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing with tokenized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.45049771693186835, pvalue=2.5356459143049236e-24)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.tokenize_data(), tp2.tokenize_data()], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('----- First group ----',\n",
              " let            51\n",
              " report         51\n",
              " lose           51\n",
              " amendment      34\n",
              " power          34\n",
              "                ..\n",
              " others         17\n",
              " separate       17\n",
              " basis          17\n",
              " accumulated    17\n",
              " hatred         17\n",
              " Length: 136, dtype: int64,\n",
              " '----- Second group -----',\n",
              " report          45\n",
              " european        41\n",
              " take            38\n",
              " parliament      37\n",
              " president       32\n",
              "                 ..\n",
              " good             1\n",
              " alone            1\n",
              " offers           1\n",
              " country          1\n",
              " enthusiastic     1\n",
              " Length: 327, dtype: int64)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'----- First group ----',tp1.frequency(True, 'cleaned'),'----- Second group -----', tp2.frequency(True, 'cleaned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('----- First group ----',\n",
              " .              391\n",
              " the            289\n",
              " ,              221\n",
              " of             153\n",
              " to             136\n",
              "               ... \n",
              " separate        17\n",
              " on              17\n",
              " basis           17\n",
              " accumulated     17\n",
              " hatred          17\n",
              " Length: 203, dtype: int64,\n",
              " '----- Second group -----',\n",
              " the             446\n",
              " .               390\n",
              " of              253\n",
              " to              205\n",
              " ,               144\n",
              "                ... \n",
              " country           1\n",
              " Vote              1\n",
              " h                 1\n",
              " enthusiastic      1\n",
              " about             1\n",
              " Length: 459, dtype: int64)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'----- First group ----',tp1.frequency(True, 'tokenized'),'----- Second group -----', tp2.frequency(True, 'tokenized')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing with lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### With cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4810231734170824, pvalue=5.904510415498371e-28)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.lemmatize_data('cleaned'), tp2.lemmatize_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### With tokenized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.45684718944780944, pvalue=4.766946098384746e-25)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.lemmatize_data('tokenized'), tp2.lemmatize_data('tokenized')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing with most common lemma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### With cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4884451179547373, pvalue=6.780872227864517e-29)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.mc_lemmatize_data('cleaned'), tp2.mc_lemmatize_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### With tokenized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4598193578111567, pvalue=2.1538267683062985e-25)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.mc_lemmatize_data('tokenized'), tp2.mc_lemmatize_data('tokenized')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Testing with lesk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.46511878367859305, pvalue=5.1234758101231843e-26)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.apply_lesk_data('cleaned'), tp2.apply_lesk_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.44025516061325287, pvalue=3.494129449862612e-23)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.apply_lesk_data('tokenized'), tp2.apply_lesk_data('tokenized')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Testing lesk with lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.46511878367859305, pvalue=5.1234758101231843e-26)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.apply_lesk_lemmas_data('cleaned'), tp2.apply_lesk_lemmas_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.43751386820493765, pvalue=6.946178670452206e-23)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.apply_lesk_lemmas_data('tokenized'), tp2.apply_lesk_lemmas_data('tokenized')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing with name entities NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4679440754704449, pvalue=2.358310094026997e-26)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.name_entities_nltk('cleaned'), tp2.name_entities_nltk('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4499943169285951, pvalue=2.8905921464511112e-24)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.name_entities_nltk('tokenized'), tp2.name_entities_nltk('tokenized')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Name entities NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4493107049487957, pvalue=3.452252846323494e-24)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pearsonr(dt['gs'],compute_metrics([tp1.name_entities_spacy(), tp2.name_entities_spacy()], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing on training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from text_processing import text_processing, compute_metrics\n",
        "from scipy.stats import pearsonr\n",
        "from collections import Counter\n",
        "import io\n",
        "europarl = pd.read_csv('Complementary Material/train/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "europarl['gs'] = pd.read_csv('Complementary Material/train/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "\n",
        "vid = pd.read_csv('Complementary Material/train/STS.input.MSRvid.txt',sep='\\t',header=None)\n",
        "vid['gs'] = pd.read_csv('Complementary Material/train/STS.gs.MSRvid.txt',sep='\\t',header=None)\n",
        "\n",
        "with open('Complementary Material/train/STS.input.MSRpar.txt') as f:\n",
        "    lines = f.readlines()\n",
        "for index in range(len(lines)):\n",
        "    lines[index] = lines[index].replace('\\\"', ' ')\n",
        "par = pd.read_csv(io.StringIO(''.join(lines)), sep='\\t',header=None, on_bad_lines='warn')\n",
        "par['gs'] = pd.read_csv('Complementary Material/train/STS.gs.MSRpar.txt',sep='\\t',header=None)\n",
        "\n",
        "total = pd.concat([europarl, vid, par]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n",
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.44013235092459513, pvalue=3.963249990137324e-36)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eur_tp1 = text_processing(europarl[0])\n",
        "eur_tp2 = text_processing(europarl[1])\n",
        "pearsonr(europarl['gs'],compute_metrics([eur_tp1.mc_lemmatize_data('cleaned'), eur_tp2.mc_lemmatize_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n",
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.743585243920414, pvalue=6.8783591678791514e-133)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vid_tp1 = text_processing(vid[0])\n",
        "vid_tp2 = text_processing(vid[1])\n",
        "pearsonr(vid['gs'],compute_metrics([vid_tp1.mc_lemmatize_data('cleaned'), vid_tp2.mc_lemmatize_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n",
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4607370310110359, pvalue=1.1031499896752255e-40)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "par_tp1 = text_processing(par[0])\n",
        "par_tp2 = text_processing(par[1])\n",
        "pearsonr(par['gs'],compute_metrics([par_tp1.mc_lemmatize_data('cleaned'), par_tp2.mc_lemmatize_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n",
            "\n",
            " -- Data hasn't been cleaned, to apply most_common_lemma to data is going to be cleaned with the default parameters --\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.605690059448885, pvalue=8.285888569412453e-224)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_tp1 = text_processing(total[0])\n",
        "total_tp2 = text_processing(total[1])\n",
        "pearsonr(total['gs'],compute_metrics([total_tp1.mc_lemmatize_data('cleaned'), total_tp2.mc_lemmatize_data('cleaned')], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combining methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.5710296807912365, pvalue=1.5887971093998278e-193)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total1 = text_processing(total[0])\n",
        "total2 = text_processing(total[1])\n",
        "t1,t2 = total1.clean_data(), total2.clean_data()\n",
        "pearsonr(total['gs'],compute_metrics([t1, t2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.5710296807912365, pvalue=1.5887971093998278e-193)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1,t2 = total_tp1.name_entities_nltk(data = t1), total_tp1.name_entities_nltk(data = t2)\n",
        "pearsonr(total['gs'],compute_metrics([t1, t2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.6028411708465875, pvalue=3.5388242418854675e-221)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1,t2 = total_tp1.lemmatize_data(data = t1), total_tp1.lemmatize_data(data = t2)\n",
        "pearsonr(total['gs'],compute_metrics([t1, t2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.6033214913285423, pvalue=1.2800280496346832e-221)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1,t2 = total_tp1.mc_lemmatize_data(data = t1), total_tp1.mc_lemmatize_data(data = t2)\n",
        "pearsonr(total['gs'],compute_metrics([t1, t2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing in all test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from text_processing import text_processing, compute_metrics\n",
        "from scipy.stats import pearsonr\n",
        "from collections import Counter\n",
        "import io\n",
        "europarl = pd.read_csv('Complementary Material/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "europarl['gs'] = pd.read_csv('Complementary Material/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "\n",
        "vid = pd.read_csv('Complementary Material/test-gold/STS.input.MSRvid.txt',sep='\\t',header=None)\n",
        "vid['gs'] = pd.read_csv('Complementary Material/test-gold/STS.gs.MSRvid.txt',sep='\\t',header=None)\n",
        "\n",
        "with open('Complementary Material/test-gold/STS.input.MSRpar.txt', encoding='utf8') as f:\n",
        "    lines = f.readlines()\n",
        "for index in range(len(lines)):\n",
        "    lines[index] = lines[index].replace('\\\"', ' ')\n",
        "par = pd.read_csv(io.StringIO(''.join(lines)), sep='\\t',header=None, on_bad_lines='warn')\n",
        "par['gs'] = pd.read_csv('Complementary Material/train/STS.gs.MSRpar.txt',sep='\\t',header=None)\n",
        "\n",
        "onwn = pd.read_csv('Complementary Material/test-gold/STS.input.surprise.OnWN.txt',sep='\\t',header=None)\n",
        "onwn['gs'] = pd.read_csv('Complementary Material/test-gold/STS.gs.surprise.OnWN.txt',sep='\\t',header=None)\n",
        "\n",
        "news = pd.read_csv('Complementary Material/test-gold/STS.input.surprise.SMTnews.txt',sep='\\t',header=None)\n",
        "news['gs'] = pd.read_csv('Complementary Material/test-gold/STS.gs.surprise.SMTnews.txt',sep='\\t',header=None) \n",
        "\n",
        "total = pd.concat([europarl, vid, par, onwn, news]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.4995786249880646, pvalue=6.391329307838565e-196)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total1 = text_processing(total[0])\n",
        "total2 = text_processing(total[1])\n",
        "t1,t2 = total1.clean_data(), total2.clean_data()\n",
        "pearsonr(total['gs'],compute_metrics([t1, t2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PearsonRResult(statistic=-0.5279072000192514, pvalue=1.2589492545201208e-222)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1,t2 = total_tp1.mc_lemmatize_data(data = t1), total_tp1.mc_lemmatize_data(data = t2)\n",
        "pearsonr(total['gs'],compute_metrics([t1, t2], ['jaccard']).do()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The leaders have now been given a new chance and let us hope they seize it.',\n",
              " \"The leaders benefit aujourd' hui of a new luck and let's let them therefore seize it.\")"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total[0][0], total[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "r1,r2 = total1.mc_lemmatize_data(lemma = True)[0],total2.mc_lemmatize_data(lemma = True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Lemma('leader.n.01.leader'),\n",
              " Lemma('give.v.01.give'),\n",
              " Lemma('new.a.01.new'),\n",
              " Lemma('opportunity.n.01.chance'),\n",
              " Lemma('let.v.01.let'),\n",
              " None,\n",
              " Lemma('seize.v.01.seize')]"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools as it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "combs = list(it.product(r1,r2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Lemma('leader.n.01.leader'),\n",
              " Lemma('give.v.01.give'),\n",
              " Lemma('new.a.01.new'),\n",
              " Lemma('opportunity.n.01.chance'),\n",
              " Lemma('let.v.01.let'),\n",
              " None,\n",
              " Lemma('seize.v.01.seize')]"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Lemma('leader.n.01.leader'),\n",
              " Lemma('profit.v.01.benefit'),\n",
              " None,\n",
              " None,\n",
              " Lemma('new.a.01.new'),\n",
              " Lemma('fortune.n.04.fortune'),\n",
              " Lemma('lashkar-e-taiba.n.01.Lashkar-e-Taiba'),\n",
              " Lemma('let.v.01.let'),\n",
              " Lemma('therefore.r.01.therefore'),\n",
              " Lemma('seize.v.01.seize')]"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "def path_similarities(lemmas1,lemmas2):\n",
        "    combs = list(it.product(lemmas1,lemmas2))\n",
        "    return [pair[0].synset().path_similarity(pair[1].synset()) for pair in combs if pair[0] and pair[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({1.0: 4,\n",
              "         0.1111111111111111: 7,\n",
              "         0.125: 9,\n",
              "         0.1: 6,\n",
              "         0.08333333333333333: 2,\n",
              "         0.25: 9,\n",
              "         0.3333333333333333: 7,\n",
              "         0.09090909090909091: 2,\n",
              "         0.16666666666666666: 1,\n",
              "         0.2: 1})"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(path_similarities(r1,r2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "l1 = total1.lemmatize_data(r_pos_tag = False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "l2 = total2.lemmatize_data(r_pos_tag = False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def path_similarities2(lemmas1,lemmas2):\n",
        "    synsets1 = wn.synsets(lemmas1)\n",
        "    synsets2 = wn.synsets(lemmas2)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('give.n.01'),\n",
              " Synset('give.v.01'),\n",
              " Synset('yield.v.01'),\n",
              " Synset('give.v.03'),\n",
              " Synset('give.v.04'),\n",
              " Synset('give.v.05'),\n",
              " Synset('hold.v.03'),\n",
              " Synset('give.v.07'),\n",
              " Synset('give.v.08'),\n",
              " Synset('give.v.09'),\n",
              " Synset('give.v.10'),\n",
              " Synset('render.v.04'),\n",
              " Synset('impart.v.01'),\n",
              " Synset('establish.v.05'),\n",
              " Synset('give.v.14'),\n",
              " Synset('give.v.15'),\n",
              " Synset('sacrifice.v.01'),\n",
              " Synset('pass.v.05'),\n",
              " Synset('give.v.18'),\n",
              " Synset('give.v.19'),\n",
              " Synset('give.v.20'),\n",
              " Synset('give.v.21'),\n",
              " Synset('grant.v.05'),\n",
              " Synset('move_over.v.01'),\n",
              " Synset('feed.v.02'),\n",
              " Synset('contribute.v.02'),\n",
              " Synset('collapse.v.01'),\n",
              " Synset('give.v.27'),\n",
              " Synset('give.v.28'),\n",
              " Synset('give.v.29'),\n",
              " Synset('afford.v.04'),\n",
              " Synset('give.v.31'),\n",
              " Synset('give.v.32'),\n",
              " Synset('give.v.33'),\n",
              " Synset('give.v.34'),\n",
              " Synset('give.v.35'),\n",
              " Synset('give.v.36'),\n",
              " Synset('give.v.37'),\n",
              " Synset('give.v.38'),\n",
              " Synset('give.v.39'),\n",
              " Synset('give.v.40'),\n",
              " Synset('give.v.41'),\n",
              " Synset('give.v.42'),\n",
              " Synset('give.v.43'),\n",
              " Synset('give.v.44')]"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wn.synsets(total1.lemmatize_data(r_pos_tag = False)[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "t1,t2 = nltk.pos_tag(r1), nltk.pos_tag(r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "match = {'JJ':\"a\", 'JJ':\"s\", 'RB':\"r\", 'NN':\"n\", 'VB':\"v\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "s1,s2 = wn.synsets(t1[2][0], match[t1[2][1]]), wn.synsets(t2[2][0], match[t2[2][1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([Synset('new.a.01'),\n",
              "  Synset('fresh.s.04'),\n",
              "  Synset('raw.s.12'),\n",
              "  Synset('new.s.04'),\n",
              "  Synset('new.s.05'),\n",
              "  Synset('new.a.06'),\n",
              "  Synset('newfangled.s.01'),\n",
              "  Synset('new.s.08'),\n",
              "  Synset('modern.s.05'),\n",
              "  Synset('new.s.10'),\n",
              "  Synset('new.s.11')],\n",
              " [Synset('new.a.01'),\n",
              "  Synset('fresh.s.04'),\n",
              "  Synset('raw.s.12'),\n",
              "  Synset('new.s.04'),\n",
              "  Synset('new.s.05'),\n",
              "  Synset('new.a.06'),\n",
              "  Synset('newfangled.s.01'),\n",
              "  Synset('new.s.08'),\n",
              "  Synset('modern.s.05'),\n",
              "  Synset('new.s.10'),\n",
              "  Synset('new.s.11')])"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s1,s2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "l = Counter([j for i in s1 for j in i.lemmas()]).most_common(1)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Lemma('new.a.01.new')]\n",
            "[Lemma('fresh.s.04.fresh'), Lemma('fresh.s.04.new'), Lemma('fresh.s.04.novel')]\n",
            "[Lemma('raw.s.12.raw'), Lemma('raw.s.12.new')]\n",
            "[Lemma('new.s.04.new'), Lemma('new.s.04.unexampled')]\n",
            "[Lemma('new.s.05.new')]\n",
            "[Lemma('new.a.06.new')]\n",
            "[Lemma('newfangled.s.01.newfangled'), Lemma('newfangled.s.01.new')]\n",
            "[Lemma('new.s.08.New')]\n",
            "[Lemma('modern.s.05.Modern'), Lemma('modern.s.05.New')]\n",
            "[Lemma('new.s.10.new'), Lemma('new.s.10.young')]\n",
            "[Lemma('new.s.11.new')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(len(s1)):\n",
        "    print(s1[i].lemmas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Lemma('newfangled.s.01.new')"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s1[6].lemmas()[1]#.synset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_n(n,p):\n",
        "    if p:\n",
        "        return n\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(print_n(5,False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('leaders', 'leaders')"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w1,w2 = total1.clean_data()[0][0], total2.clean_data()[0][0]\n",
        "w1,w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('leaders', 'NNS'),\n",
              " ('given', 'VBN'),\n",
              " ('new', 'JJ'),\n",
              " ('chance', 'NN'),\n",
              " ('let', 'VBD'),\n",
              " ('hope', 'PRP'),\n",
              " ('seize', 'VB')]"
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags1 =nltk.pos_tag(total1.clean_data()[0])\n",
        "tags1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('leaders', 'n')"
            ]
          },
          "execution_count": 270,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags1[0][0], tags1[0][1][0].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Synset('leadership.n.02'), Synset('leader.n.01'), Synset('drawing_card.n.02')]"
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synsets1 = wn.synsets(tags1[0][0], tags1[0][1][0].lower())\n",
        "synsets1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Lemma('drawing_card.n.02.leader'),\n",
              " Lemma('drawing_card.n.02.loss_leader'),\n",
              " Lemma('drawing_card.n.02.drawing_card'),\n",
              " Lemma('leader.n.01.leader'),\n",
              " Lemma('leadership.n.02.leaders'),\n",
              " Lemma('leadership.n.02.leadership')]"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[lemma for synset in synsets1 for lemma in synset.lemmas()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Synset('leader.n.01')"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter([lemma for synset in synsets1 for lemma in synset.lemmas()]).most_common(1)[0][0].synset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "wnl = nltk.stem.WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'leader'"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wnl.lemmatize('leaders', 'n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('IHLT')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0795eca24a98e58b2dcbec80c9554a91f94c5c7d4e675f06c8c2f85c434623a5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
