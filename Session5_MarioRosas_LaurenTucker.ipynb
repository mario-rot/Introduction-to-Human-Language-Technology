{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mario-rot/Introduction-to-Human-Language-Technology/blob/main/Session5_MarioRosas_LaurenTucker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F_KjPu9CYgQ"
   },
   "source": [
    "# Lab session 5 (Lexical Semantics) - IHLT\n",
    "\n",
    "**Students:** Lauren Tucker & Mario Rosas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba8Vq6iycNlB"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTkCEXT-Dg3i",
    "outputId": "b5de31ea-de6c-4d61-f131-2576ff4801d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZhQnviXLEejR"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkYnjqi-cSl4"
   },
   "source": [
    "### Manual filtering of available PoS tags for synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ewQG0J2vGDId"
   },
   "outputs": [],
   "source": [
    "match = {'JJ':\"a\", 'JJ':\"s\", 'RB':\"r\", 'NN':\"n\", 'VB':\"v\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3UNgaytKCW4Q"
   },
   "outputs": [],
   "source": [
    "data = [('man', 'NN'), ('swim','VB'), ('girl','NN'), ('boy', 'NN'),  ('woman', 'NN'), ('walk', 'VB')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgCf_xEoc8vC"
   },
   "source": [
    "### Getting the most common lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOmziGTJmCU-",
    "outputId": "8cc944df-cde6-4c90-802f-60bba7252e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Lemma('man.n.01.man'), 10),\n",
       " (Lemma('swim.v.01.swim'), 5),\n",
       " (Lemma('girl.n.01.girl'), 5),\n",
       " (Lemma('male_child.n.01.boy'), 4),\n",
       " (Lemma('woman.n.01.woman'), 4),\n",
       " (Lemma('walk.v.01.walk'), 10)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [Counter([j for i in wn.synsets(data[r][0], match[data[r][1]]) for j in i.lemmas()]).most_common(1)[0] for r in range(len(data))]\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AmgKSc6d0I2"
   },
   "source": [
    "### Definition of the most common lema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAS5paEwDuGX",
    "outputId": "42b6ae24-15bb-43e9-b882-7b89ab6a9940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('man.n.01') an adult person who is male (as opposed to a woman)\n",
      "Synset('swim.v.01') travel through water\n",
      "Synset('girl.n.01') a young woman\n",
      "Synset('male_child.n.01') a youthful male person\n",
      "Synset('woman.n.01') an adult female person (as opposed to a man)\n",
      "Synset('walk.v.01') use one's feet to advance; advance by steps\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i,j in enumerate(data):\n",
    "   res[data[i][0]] = wn.synsets(data[i][0], match[data[i][1]])[0]\n",
    "   print(res[data[i][0]], res[data[i][0]].definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PItzwhgJeSFW"
   },
   "source": [
    "### Preparing data to calculate similiaty metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZiNOhbLpLaYn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZtBT8fjDXwZE"
   },
   "outputs": [],
   "source": [
    "pairs = np.array(np.meshgrid(list(res.keys()), list(res.keys()))).T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zd_-819enHG"
   },
   "source": [
    "### Getting the least common subsumer (LCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "0GwxHNYcgwDG",
    "outputId": "d979bd9c-4296-4c0e-a8fe-feda98c669c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>swim</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>[Synset('man.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('swim.v.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('girl.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>[Synset('male.n.02')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('male_child.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>[Synset('adult.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[Synset('person.n.01')]</td>\n",
       "      <td>[Synset('woman.n.01')]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('travel.v.01')]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Synset('walk.v.01')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          man                     swim  \\\n",
       "man      [Synset('man.n.01')]                       []   \n",
       "swim                       []    [Synset('swim.v.01')]   \n",
       "girl   [Synset('adult.n.01')]                       []   \n",
       "boy     [Synset('male.n.02')]                       []   \n",
       "woman  [Synset('adult.n.01')]                       []   \n",
       "walk                       []  [Synset('travel.v.01')]   \n",
       "\n",
       "                          girl                          boy  \\\n",
       "man     [Synset('adult.n.01')]        [Synset('male.n.02')]   \n",
       "swim                        []                           []   \n",
       "girl     [Synset('girl.n.01')]      [Synset('person.n.01')]   \n",
       "boy    [Synset('person.n.01')]  [Synset('male_child.n.01')]   \n",
       "woman   [Synset('woman.n.01')]      [Synset('person.n.01')]   \n",
       "walk                        []                           []   \n",
       "\n",
       "                         woman                     walk  \n",
       "man     [Synset('adult.n.01')]                       []  \n",
       "swim                        []  [Synset('travel.v.01')]  \n",
       "girl    [Synset('woman.n.01')]                       []  \n",
       "boy    [Synset('person.n.01')]                       []  \n",
       "woman   [Synset('woman.n.01')]                       []  \n",
       "walk                        []    [Synset('walk.v.01')]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs = []\n",
    "for i, pair in enumerate(pairs):\n",
    "  lcs.append(res[pair[0]].lowest_common_hypernyms(res[pair[1]]))\n",
    "\n",
    "lcs = np.array(lcs, dtype=object).reshape((6,6))\n",
    "\n",
    "df_lcs = pd.DataFrame(lcs)\n",
    "df_lcs.columns = list(res.keys())\n",
    "df_lcs.index = list(res.keys())\n",
    "\n",
    "df_lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIcGV9GFewFx"
   },
   "source": [
    "### Getting the Path Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HBMe8QFXfrgR"
   },
   "outputs": [],
   "source": [
    "path_sim = []\n",
    "for i, pair in enumerate(pairs):\n",
    "  path_sim.append(res[pair[0]].path_similarity(res[pair[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "IYnQmvjmf6a0",
    "outputId": "d4aa6dde-cb3f-4476-a417-f4624e85a7ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>swim</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            man      swim      girl       boy     woman      walk\n",
       "man         1.0       0.1      0.25  0.333333  0.333333       0.1\n",
       "swim        0.1       1.0  0.090909       0.1       0.1  0.333333\n",
       "girl       0.25  0.090909       1.0  0.166667       0.5  0.090909\n",
       "boy    0.333333       0.1  0.166667       1.0       0.2       0.1\n",
       "woman  0.333333       0.1       0.5       0.2       1.0       0.1\n",
       "walk        0.1  0.333333  0.090909       0.1       0.1       1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_sim = np.array(path_sim, dtype=object).reshape((6,6))\n",
    "\n",
    "df_path_sim = pd.DataFrame(path_sim)\n",
    "df_path_sim.columns = list(res.keys())\n",
    "df_path_sim.index = list(res.keys())\n",
    "\n",
    "df_path_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zou8NOaPe2bZ"
   },
   "source": [
    "### Getting the Leacock-Chodorow Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "znt5vXIvgPXJ",
    "outputId": "67472524-8495-4b67-821c-72dc87dcf4b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>swim</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618897</td>\n",
       "      <td>0.697983</td>\n",
       "      <td>0.697983</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.618897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507432</td>\n",
       "      <td>0.809449</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.697983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.697983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.809449</td>\n",
       "      <td>0.557553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            man      swim      girl       boy     woman      walk\n",
       "man         1.0       0.0  0.618897  0.697983  0.697983       0.0\n",
       "swim        0.0       1.0       0.0       0.0       0.0  0.662805\n",
       "girl   0.618897       0.0       1.0  0.507432  0.809449       0.0\n",
       "boy    0.697983       0.0  0.507432       1.0  0.557553       0.0\n",
       "woman  0.697983       0.0  0.809449  0.557553       1.0       0.0\n",
       "walk        0.0  0.662805       0.0       0.0       0.0       1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lch = []\n",
    "for i, pair in enumerate(pairs):\n",
    "  try:\n",
    "     lch.append(res[pair[0]].lch_similarity(res[pair[1]]))\n",
    "  except:\n",
    "    lch.append(0)\n",
    "\n",
    "# lch = np.array(lch)\n",
    "# lch /= lch.max()\n",
    "lch = np.array(lch, dtype=object).reshape((6,6))\n",
    "\n",
    "df_lch = pd.DataFrame(lch)\n",
    "df_lch.columns = list(res.keys())\n",
    "df_lch.index = list(res.keys())\n",
    "\n",
    "for column in df_lch.columns:\n",
    "  df_lch[column] /= df_lch[column].max()\n",
    "\n",
    "df_lch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr6fVfB4fDYj"
   },
   "source": [
    "### Getting the Wu-Palmer Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "7FWL8_tYjI_Q",
    "outputId": "1a1117d1-ec64-4c85-9d2f-4aa0d3b765a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>swim</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            man      swim      girl       boy     woman      walk\n",
       "man         1.0  0.181818  0.631579  0.666667  0.666667  0.181818\n",
       "swim   0.181818       1.0  0.166667  0.181818  0.181818  0.333333\n",
       "girl   0.631579  0.166667       1.0  0.631579  0.631579  0.166667\n",
       "boy    0.666667  0.181818  0.631579       1.0  0.666667  0.181818\n",
       "woman  0.666667  0.181818  0.947368  0.666667       1.0  0.181818\n",
       "walk   0.181818  0.333333  0.166667  0.181818  0.181818       1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wup = []\n",
    "for i, pair in enumerate(pairs):\n",
    "  wup.append(res[pair[0]].wup_similarity(res[pair[1]]))\n",
    "\n",
    "wup = np.array(wup, dtype=object).reshape((6,6))\n",
    "\n",
    "df_wup = pd.DataFrame(wup)\n",
    "df_wup.columns = list(res.keys())\n",
    "df_wup.index = list(res.keys())\n",
    "\n",
    "df_wup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4_yV7dufTlt"
   },
   "source": [
    "### Getting the Lin Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "F3b8Ftn2jOsJ",
    "outputId": "154cdc26-ef5b-4f26-831a-bc636d06e266"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\mario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>man</th>\n",
       "      <th>swim</th>\n",
       "      <th>girl</th>\n",
       "      <th>boy</th>\n",
       "      <th>woman</th>\n",
       "      <th>walk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713511</td>\n",
       "      <td>0.729472</td>\n",
       "      <td>0.787084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.713511</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.292728</td>\n",
       "      <td>0.90678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>0.729472</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.318423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.787084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90678</td>\n",
       "      <td>0.318423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walk</th>\n",
       "      <td>0</td>\n",
       "      <td>0.491005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            man      swim      girl       boy     woman      walk\n",
       "man         1.0         0  0.713511  0.729472  0.787084         0\n",
       "swim          0       1.0         0         0         0  0.491005\n",
       "girl   0.713511         0       1.0  0.292728   0.90678         0\n",
       "boy    0.729472         0  0.292728       1.0  0.318423         0\n",
       "woman  0.787084         0   0.90678  0.318423       1.0         0\n",
       "walk          0  0.491005         0         0         0       1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet_ic')\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "lin = []\n",
    "for i, pair in enumerate(pairs):\n",
    "  try:\n",
    "    lin.append(res[pair[0]].lin_similarity(res[pair[1]],brown_ic))\n",
    "  except:\n",
    "    lin.append(0)\n",
    "\n",
    "lin = np.array(lin, dtype=object).reshape((6,6))\n",
    "\n",
    "df_lin = pd.DataFrame(lin)\n",
    "df_lin.columns = list(res.keys())\n",
    "df_lin.index = list(res.keys())\n",
    "\n",
    "df_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgYgifa0d1Wj"
   },
   "source": [
    "## Conclusion:\n",
    "*Choosing the best algorithm for calculating the similaity is a subjective decision, since deciding which has the best performance depends on the user's interpretations of which words are the most similar. For example, are \"man\" and \"woman\" more similar to each other than \"man\" and \"boy\"? Using Path Similarity, for instance, \"man\"  and \"boy\" have a similarity score of 0.333333, even though in our opinion, these two words are more than just slightly similar. On the other hand, Leacock-Chodorow provides higher similarity values for this pairing, at 0.697983, however, the difference between this similarity value and the one between \"man\" and \"girl\" is very small. Having such a small difference makes it more difficult to numerically distinguish differences between words. Wu-Palmer and Lin also have this issue, with even smaller differences between their two respective similarity values, making the two words even harder to distinguish. Nevertheless,  Lin method more often provides the highest similarity values for the words that we personally believe are extremely similar. One counterexample to this is that we would expect \"boy\" and \"girl\" to be very similar, however, their similarity score is only 0.292728, compared to the higher values found in the table that were closer to ~0.7.*\n",
    "\n",
    "*Path Similarity and Wu-Palmer were the only two algorithms that allowed for the direct comparison between nouns and verbs. This could be advantageous in situations where you need to distingsh between words from different classes when performing nummerical analysis or when in some contexts, some words change their class. On some other cases, it could provide inaccurate similarity values when values of words ot the same type have also lower values.*\n",
    "\n",
    "*While Path Similarity does not provide numerical similarity values, it is helpful in context analysis to determine similarity using a common word between the two, which provides even greater context.*\n",
    "\n",
    "*It is also interesting to notice that in all of the \n",
    "man/boy and woman/girl similarity values, the woman/girl similarity is always higher than the man/boy similarity, even though in both cases, it is a comparison between an adult and a child version of the same gender.*\n",
    "\n",
    "*In conclusion, the algorithm that appears to perform best is the Wu-Palmer algorithm, since the similarity values it provides most closely align with our personal perceptions of the word similarities. Although Leacock-Chodorow has a similar performance, Wu-Palmer has the advantage in that it is able to directly compare nouns and verbs, unlike Leacock-Chodorow.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from text_processing import text_processing\n",
    "dt = pd.read_csv('Complementary Material/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
    "dt['gs'] = pd.read_csv('Complementary Material/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = {'j':\"s\", 'j':\"a\", 'r':\"r\", 'n':\"n\", 'v':\"v\"}\n",
    "def get_most_common_lemma(pair):\n",
    "    print(pair)\n",
    "    print(wn.synsets(pair[0]))\n",
    "    return Counter([j for i in wn.synsets(pair[0], match[pair[1][0].lower()]) for j in i.lemmas()]).most_common(1)[0][0]\n",
    "\n",
    "def mcLemma_sentece(sentence):\n",
    "    print(nltk.pos_tag(sentence))\n",
    "    return[get_most_common_lemma(word) for word in nltk.pos_tag(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = {'j':\"s\", 'j':\"a\", 'r':\"r\", 'n':\"n\", 'v':\"v\"}\n",
    "def get_most_common_lemma(pair):\n",
    "    synsets = wn.synsets(pair[0], match[pair[1][0].lower()])\n",
    "    if synsets != []:\n",
    "        return Counter([j for i in synsets for j in i.lemmas()]).most_common(1)[0][0]\n",
    "    else:\n",
    "        return Counter([j for i in wn.synsets(pair[0]) for j in i.lemmas()]).most_common(1)[0][0]\n",
    "\n",
    "def most_common_lemma_sentece(sentence):\n",
    "    return[get_most_common_lemma(word) for word in nltk.pos_tag(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'consequently '+' '.join([i for i in dt[:5][0]])\n",
    "tp = text_processing([s]).clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('consequently.r.01.consequently'),\n",
       " Lemma('leader.n.01.leader'),\n",
       " Lemma('give.v.01.give'),\n",
       " Lemma('new.a.01.new'),\n",
       " Lemma('opportunity.n.01.chance'),\n",
       " Lemma('let.v.01.let'),\n",
       " Lemma('hope.v.01.hope'),\n",
       " Lemma('seize.v.01.seize'),\n",
       " Lemma('amendment.n.01.amendment'),\n",
       " Lemma('propose.v.01.propose'),\n",
       " Lemma('certain.s.01.certain'),\n",
       " Lemma('change.n.01.change'),\n",
       " Lemma('mention.n.01.reference'),\n",
       " Lemma('paragraph.v.01.paragraph'),\n",
       " Lemma('let.v.01.let'),\n",
       " Lemma('remind.v.01.remind'),\n",
       " Lemma('allies.n.01.Allies'),\n",
       " Lemma('include.v.01.include'),\n",
       " Lemma('ardent.s.01.fervent'),\n",
       " Lemma('supporter.n.01.supporter'),\n",
       " Lemma('tax.n.01.tax'),\n",
       " Lemma('vote.n.01.vote'),\n",
       " Lemma('take.v.01.take'),\n",
       " Lemma('topographic_point.n.01.place'),\n",
       " Lemma('today.n.01.today'),\n",
       " Lemma('fisherman.n.01.fisherman'),\n",
       " Lemma('inactive.s.01.inactive'),\n",
       " Lemma('tire.v.01.tire'),\n",
       " Lemma('defeated.s.02.defeated')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_lemma_sentece(tp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['consequently',\n",
       "  'leaders',\n",
       "  'given',\n",
       "  'new',\n",
       "  'chance',\n",
       "  'let',\n",
       "  'hope',\n",
       "  'seize',\n",
       "  'amendment',\n",
       "  'proposes',\n",
       "  'certain',\n",
       "  'changes',\n",
       "  'references',\n",
       "  'paragraphs',\n",
       "  'let',\n",
       "  'remind',\n",
       "  'allies',\n",
       "  'include',\n",
       "  'fervent',\n",
       "  'supporters',\n",
       "  'tax',\n",
       "  'vote',\n",
       "  'take',\n",
       "  'place',\n",
       "  'today',\n",
       "  'fishermen',\n",
       "  'inactive',\n",
       "  'tired',\n",
       "  'disappointed']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fishermen', 'NNS'), ('inactive', 'VBP')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tp[0][-4:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('inactive.s.01'), Synset('inactive.a.02'), Synset('nonoperational.a.01'), Synset('inactive.a.04'), Synset('dormant.a.02'), Synset('passive.a.01'), Synset('inactive.a.07'), Synset('inactive.a.08'), Synset('inactive.a.09'), Synset('inactive.s.10')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets('inactive', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'consequently'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('consequently')[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['walk'].pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.wordnet import VERB, NOUN, ADJ, ADV, ADJ_SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADJ_SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match['j']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ba8Vq6iycNlB",
    "FkYnjqi-cSl4",
    "RgCf_xEoc8vC",
    "_AmgKSc6d0I2",
    "PItzwhgJeSFW"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('IHLT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0795eca24a98e58b2dcbec80c9554a91f94c5c7d4e675f06c8c2f85c434623a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
